# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tLgqqZClUqDFXSAcxwq2MDqoYh9Bi_jV
"""

from google.colab import drive
drive.mount('/content/drive') # Mount to the default location

# Import os to interact with the file system
import os

# Define the path to your dataset within your Google Drive
dataset_path = '/content/drive/MyDrive/Datasets'

# Check if the directory exists
if not os.path.exists(dataset_path):
    # If it doesn't exist, create it
    os.makedirs(dataset_path)
    print(f"Created directory: {dataset_path}")
else:
    print(f"Directory already exists: {dataset_path}")

# Now you can access your dataset at 'dataset_path'

import pandas as pd
# Assuming the dataset is in the location specified in the Google Drive mount section
df = pd.read_csv('/content/drive/MyDrive/Datasets/wine_quality_classification.csv')
df = df[df['quality_label'].notna()] # remove any NaN values as it blows up serialization
data = df.sample(700).to_dict('records') # Get only 700 records. More records will make it slower to index
len(data)

df.head()

!pip install qdrant-client
!pip install sentence-transformers

from qdrant_client import models, QdrantClient
from sentence_transformers import SentenceTransformer

encoder = SentenceTransformer('all-MiniLM-L6-v2')

qdrant = QdrantClient(":memory:")

qdrant.recreate_collection(
    collection_name="top_wines",
    vectors_config=models.VectorParams(
        size=encoder.get_sentence_embedding_dimension(), # Vector size is defined by used model
        distance=models.Distance.COSINE
    )
)

# vectorize!
qdrant.upload_points(
    collection_name="top_wines",
    points=[
        models.PointStruct(
            id=idx,
            vector=encoder.encode(doc["quality_label"]).tolist(),
            payload=doc,
        ) for idx, doc in enumerate(data) # data is the variable holding all the wines
    ]
)

user_prompt = "Suggest me a low quality wine of density less than 1 and alcohol content less than 8.4%"

hits = qdrant.search(
    collection_name="top_wines",
    query_vector=encoder.encode(user_prompt).tolist(),
    limit=3
)
for hit in hits:
  print(hit.payload, "score:", hit.score)

# define a variable to hold the search results
search_results = [hit.payload for hit in hits]

!pip install OpenAI

!python3 -m llama_cpp.server --chat --host 127.0.0.1 --port 8080

!pip install llama-cpp-python --quiet

!curl http://127.0.0.1:8080/v1/models

!pip install --upgrade openai

from openai import OpenAI

# Create client instance with your API key
client = OpenAI(api_key="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")

response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a chatbot, a wine specialist. Your top priority is to help guide users into selecting amazing wine and guide them with their requests."},
        {"role": "user", "content": "Suggest me a low quality wine of density less than 1 and alcohol content less than 8.4%"},
        {"role": "assistant", "content": str(search_results)}
        ]
)

print(response.choices[0].message.content)